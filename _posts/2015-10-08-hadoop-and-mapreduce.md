---
layout: post
title: "Big Data with Hadoop and MapReduce"
comments: True
---

### Intro to Hadoop and MapReduce

#### 3 V's of Big Data

Volume: huge storage space needed.

Variety: unstructured data, no schema for SQL.

Velocity: data is generated extremely fast

Hadoop solves all three problems: stores and processes mass amount of data efficiently.

#### Doug Cutting: How Hadoop Came To Be

Google published a paper about GFS, their distributed file system, and MapReduce. Doug Cutting and his
partner implemented it in open-source.

Hadoop started from 20-30 machines to process petabytes of data, and scaled to thousands of processors.
They made it a general-purpose platform for big data. It has tools to allow people to do MapReduce programming
more easily, using SQL, Pig, Impala, etc.

Why the name Hadoop? Yellow elephant?

Doug Cuttings infant son called a yellow elephant toy "hadoop", a made-up word.

#### Core Hadoop and Hadoop Ecosystem

- Store files in Hadoop Distributed File System (HDFS)
- Process with MapReduce

Doing the processing in-place in a cluster of mid-range servers.

##### Other open-source projects for non-programmers to use Hadoop

**Hive**: uses SQL-like queries and its interpreter translates to MapReduce code.

**Pig**: simple script language that turns into MapReduce code.

Hive and Pig are based on MapReduce so they still require a substantial amount of time to run.
Another project is Impala.

**Impala**: not based on MapReduce. A way to query data with SQL, directly access data in HDFS,
optimized for low-latency (fast) queries. Much faster than Hive. Hive is optimized for long, batch processing jobs.

Others:

**Sqoop**: takes data from traditional relational database, such as Microsoft SQL server, and puts it in HDFS as 
delimited files so that it can be processed with other data on the cluster.

**Flume**: ingests data to the cluster as it's generated by external systems.

**HBase**: realtime database on top of HDFS.

**Hue**: graphical front end of the cluster.

**Oozie**: workflow management tool.

**Mahout**: machine learning library.

...

Cloudera made CDH (Cloudera Distribution including Apache Hadoop) that takes all the ecosystem projects along
with Hadoop so that the installation and integration can be easier.

### HDFS and MapReduce








